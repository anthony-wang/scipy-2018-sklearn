{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough (underfitting), and cannot model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"80%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model complexity and generalization by trying several hyperparameter settings.\n",
    "\n",
    "Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data --- for example, the weight coefficients of a linear regression model); the number of $k$ in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.582149\n",
      "n_neighbors: 3, average score: 0.707403\n",
      "n_neighbors: 5, average score: 0.729022\n",
      "n_neighbors: 10, average score: 0.729256\n",
      "n_neighbors: 20, average score: 0.645679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNearestNeighbors, n_neighbors = 1 is actually overfitting, and n_neighbors = 20 is underfitting!\n",
    "\n",
    "This might sound confusing at first. But it is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.051147\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.000575\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.061483\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.095925\n",
      "C: 0.010000, gamma: 0.001000, average score: 0.001506\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.006125\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.085672\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.078230\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.001872\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.108704\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.520209\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.481628\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.165668\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.598787\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.647899\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.677940\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.549568\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.594423\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.670074\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.754639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the **keys are the parameters and the values are the settings to be tested.**\n",
    "\n",
    "To inspect training score on the different folds, the parameter ``return_train_score`` is set to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.002, test=-0.231), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.002, test=-0.019), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.009, test=-0.424), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=-0.000, test=-0.227), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=0.000, test=-0.017), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=-0.007, test=-0.421), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.007, test=-0.210), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.009, test=-0.009), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.003, test=-0.406), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.006, test=-0.213), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.009, test=-0.011), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.002, test=-0.407), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=0.000, test=-0.226), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=0.000, test=-0.017), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=-0.006, test=-0.420), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.017, test=-0.188), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.018, test=0.002), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.016, test=-0.388), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.079, test=-0.096), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.105, test=0.078), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.106, test=-0.254), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV]  C=0.01, gamma=1, score=(train=0.070, test=-0.111), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] . C=0.01, gamma=1, score=(train=0.106, test=0.059), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV]  C=0.01, gamma=1, score=(train=0.093, test=-0.273), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.019, test=-0.185), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.020, test=0.004), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.019, test=-0.385), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.160, test=0.012), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.187, test=0.174), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.212, test=-0.141), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.470, test=0.599), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.552, test=0.456), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.550, test=0.336), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.463, test=0.570), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.537, test=0.401), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.525, test=0.288), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.174, test=0.032), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.200, test=0.189), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.220, test=-0.135), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.530, test=0.698), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.654, test=0.547), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.609, test=0.428), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.634, test=0.791), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.735, test=0.587), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.678, test=0.584), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.716, test=0.819), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.775, test=0.669), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.749, test=0.657), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.533, test=0.707), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.653, test=0.541), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.609, test=0.434), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.590, test=0.772), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.723, test=0.521), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.644, test=0.527), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.633, test=0.740), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.740, test=0.583), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.683, test=0.625), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.798, test=0.804), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.818, test=0.736), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.812, test=0.741), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "C:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, **it runs fit again on all data passed to fit** (without cross-validation), to build a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7607251269095359\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> As an aside, there is also the `RandomizedSearchCV`, which does not search the entire hyperparameter space but rather samples some values (or something like that). This is more performant for a high number of hyperparameters.\n",
    "\n",
    "Also check out [Scikit-Optimize](https://scikit-optimize.github.io/) or `skopt`, which is a third-party project that uses models to optimize the hyperparameters for scikit-learn models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>-0.230655</td>\n",
       "      <td>-0.019185</td>\n",
       "      <td>-0.423910</td>\n",
       "      <td>-0.224644</td>\n",
       "      <td>0.164457</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.001830</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>-0.004187</td>\n",
       "      <td>0.003349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>-0.226811</td>\n",
       "      <td>-0.017235</td>\n",
       "      <td>-0.420605</td>\n",
       "      <td>-0.221603</td>\n",
       "      <td>0.163892</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.006605</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>-0.210203</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>-0.405763</td>\n",
       "      <td>-0.208404</td>\n",
       "      <td>0.161093</td>\n",
       "      <td>16</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>-0.213121</td>\n",
       "      <td>-0.011354</td>\n",
       "      <td>-0.407477</td>\n",
       "      <td>-0.210675</td>\n",
       "      <td>0.160916</td>\n",
       "      <td>17</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.003072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>-0.226409</td>\n",
       "      <td>-0.017033</td>\n",
       "      <td>-0.420289</td>\n",
       "      <td>-0.221295</td>\n",
       "      <td>0.163845</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>-0.006364</td>\n",
       "      <td>-0.002027</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.000332       0.00047         0.000665        0.000470   0.001   \n",
       "1       0.000332       0.00047         0.000333        0.000471   0.001   \n",
       "2       0.000000       0.00000         0.000333        0.000470   0.001   \n",
       "3       0.000665       0.00047         0.000333        0.000470   0.001   \n",
       "4       0.000332       0.00047         0.000333        0.000470    0.01   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}          -0.230655   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}          -0.226811   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}          -0.210203   \n",
       "3           1      {'C': 0.001, 'gamma': 1}          -0.213121   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}          -0.226409   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0          -0.019185          -0.423910        -0.224644        0.164457   \n",
       "1          -0.017235          -0.420605        -0.221603        0.163892   \n",
       "2          -0.009193          -0.405763        -0.208404        0.161093   \n",
       "3          -0.011354          -0.407477        -0.210675        0.160916   \n",
       "4          -0.017033          -0.420289        -0.221295        0.163845   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               20           -0.001830           -0.001808   \n",
       "1               19           -0.000113            0.000056   \n",
       "2               16            0.007124            0.009019   \n",
       "3               17            0.006016            0.009233   \n",
       "4               18            0.000071            0.000212   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0           -0.008923         -0.004187         0.003349  \n",
       "1           -0.006605         -0.002221         0.003101  \n",
       "2            0.003181          0.006441         0.002432  \n",
       "3            0.001733          0.005661         0.003072  \n",
       "4           -0.006364         -0.002027         0.003067  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.655180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.650384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.608214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.760725\n",
       "15       1           1         0.715988\n",
       "14       1         0.1         0.655180\n",
       "18      10         0.1         0.650384\n",
       "17      10        0.01         0.608214"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to **split off a separate test-set** before performing grid-search.\n",
    "\n",
    "This pattern can be seen as a **training-validation-test** split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying `GridSearchCV` with `ShuffleSplit` cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............... C=0.001, gamma=0.001, score=-0.039, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ................ C=0.001, gamma=0.01, score=-0.038, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ................. C=0.001, gamma=0.1, score=-0.030, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................... C=0.001, gamma=1, score=-0.030, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ................ C=0.01, gamma=0.001, score=-0.037, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ................. C=0.01, gamma=0.01, score=-0.024, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................... C=0.01, gamma=0.1, score=0.061, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ..................... C=0.01, gamma=1, score=0.061, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ................. C=0.1, gamma=0.001, score=-0.023, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.120, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.531, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.545, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.126, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.604, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.651, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.714, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.588, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.664, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.620, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.791, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.989, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.993, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.981, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.989, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.978, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.967, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.974, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.971, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.963, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.963, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.993, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.962, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ...................... n_neighbors=20, score=0.953, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ...................... n_neighbors=20, score=0.948, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ...................... n_neighbors=20, score=0.948, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ...................... n_neighbors=20, score=0.978, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ...................... n_neighbors=20, score=0.962, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.912, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.915, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.941, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.936, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.932, total=   0.0s\n",
      "0.9822222222222222\n",
      "{'n_neighbors': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=42)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 5, 10, 20, 50]}\n",
    "# cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose = 3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.score(X_test, y_test))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.971, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.989, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.989, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.989, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] ....................... n_neighbors=1, score=0.989, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.982, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.989, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_neighbors=3, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] ....................... n_neighbors=3, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.996, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.974, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] ....................... n_neighbors=5, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.978, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.982, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.978, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.981, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ...................... n_neighbors=10, score=0.985, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.927, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.930, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.952, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.921, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ...................... n_neighbors=50, score=0.958, total=   0.0s\n",
      "Score on test set: 0.991111\n",
      "Best parameters: {'n_neighbors': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/14_grid_search.py\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 50]}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Score on test set: %f\" % gs.score(X_test, y_test))\n",
    "print(\"Best parameters: %s\" % gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
